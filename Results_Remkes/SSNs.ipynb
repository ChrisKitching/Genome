{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the initialization and imports\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import math\n",
    "import pprint\n",
    "\n",
    "from string import ascii_lowercase\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from Bio import SeqIO, AlignIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Emboss.Applications import NeedleallCommandline\n",
    "\n",
    "# Demand Python 3.\n",
    "if sys.version_info[0] < 3:\n",
    "    print(\"Python 3 is required, but you are using Python %i.%i.%i\") % (\n",
    "        sys.version_info[0], sys.version_info[1], sys.version_info[2])\n",
    "    sys.exit(1)\n",
    "    \n",
    "# Retrieve the specific functions from ind and proteins.py\n",
    "indels_path=\"/home/maya/InDelScanner\"  # /PATH/TO/InDelScanner\n",
    "if indels_path not in sys.path:\n",
    "    sys.path.append(indels_path)\n",
    "#from indels.ind import trim_read, findEnds, endMatch, findGap, gapAlign\n",
    "\n",
    "from ipynb.fs.defs.Kinase_statistics import convert_variant_to_dict\n",
    "\n",
    "os.chdir(\"/mnt/c/Users/Maya/Dropbox/mek_results\")\n",
    "\n",
    "with open('Remkes_protein.p', 'rb') as f:\n",
    "    all_ref = pickle.load(f)\n",
    "with open('Remkes_protein_low.p', 'rb') as f:\n",
    "    low = pickle.load(f)\n",
    "\n",
    "all_ref['mek']['low-v2'] = low['mek']['low-v2']\n",
    "\n",
    "mek = {}\n",
    "for fraction in ['high', 'med']:\n",
    "    mek[fraction] = Counter(all_ref['mek'][fraction])\n",
    "mek['low-t'] = Counter(all_ref['mek']['low']) + Counter(all_ref['mek']['low-v2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set general restrictions stemming from SpliMLib library design\n",
    "aa_2 = ['A', 'Δ']\n",
    "aa_12 = ['A','G','P','Y','D','K','M','V','I','L','F','W']\n",
    "aa_13 = aa_12 +  ['Δ']\n",
    "pos_aa = {'6': aa_12, '9': aa_12, '11': aa_12, '13': aa_12, '7a': aa_13, '8a': aa_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame.from_dict(mek).fillna(0).sort_values(by=['high', 'med', 'low-t'], ascending=False).astype(int)\n",
    "df_50p = df_all.loc[(df_all['high'] >= 50) & ((df_all['high']+df_all['med']) > 2*df_all['low-t'])]\n",
    "df_20to50 = df_all.loc[(df_all['high'].isin(range(10,50))) & \n",
    "                       (df_all['high'] > df_all['med']) & \n",
    "                       ((df_all['high']+df_all['med']) > 5*df_all['low-t']) ]\n",
    "\n",
    "df_pos = df_50p.append(df_20to50)\n",
    "pos = df_pos.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering: k-medoids and hiearchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gower\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_ls = df_pos.index.tolist()\n",
    "active = {short : convert_variant_to_dict(short) for short in active_ls}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform hiearchical clustering, I need a dataframe where each column represents the AA present at one randomised position. Then, each column is a categorical variable and the columns can be compared with Gowle dissimilarity, followed by K-medioid clustering or hiearchical clustering.\n",
    "\n",
    "https://healthcare.ai/clustering-non-continuous-variables/\n",
    "\n",
    "https://www.thinkdatascience.com/post/2019-12-16-introducing-python-package-gower/\n",
    "\n",
    "https://www.researchgate.net/publication/272351873_NumPy_SciPy_Recipes_for_Data_Science_k-Medoids_Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pos = ['6', '7a', '8a', '9', '11', '13']\n",
    "\n",
    "data = {}\n",
    "for short, m_to_pos in active.items():\n",
    "    if len(m_to_pos) != len(valid_pos):\n",
    "        continue\n",
    "    else:\n",
    "        data[short] = [m_to_pos[i] for i in valid_pos]\n",
    "\n",
    "factors = pd.DataFrame.from_dict(data, orient='index', columns=valid_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>7a</th>\n",
       "      <th>8a</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6L/7aI/8aA/9L/11F/13M</th>\n",
       "      <td>L</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6F/7aP/9W/11L/13M</th>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>Δ</td>\n",
       "      <td>W</td>\n",
       "      <td>L</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6L/7aF/9L/11I/13I</th>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>Δ</td>\n",
       "      <td>L</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6A/7aI/8aA/9L/11L/13I</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6W/7aI/9F/11L/13V</th>\n",
       "      <td>W</td>\n",
       "      <td>I</td>\n",
       "      <td>Δ</td>\n",
       "      <td>F</td>\n",
       "      <td>L</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       6 7a 8a  9 11 13\n",
       "6L/7aI/8aA/9L/11F/13M  L  I  A  L  F  M\n",
       "6F/7aP/9W/11L/13M      F  P  Δ  W  L  M\n",
       "6L/7aF/9L/11I/13I      L  F  Δ  L  I  I\n",
       "6A/7aI/8aA/9L/11L/13I  A  I  A  L  L  I\n",
       "6W/7aI/9F/11L/13V      W  I  Δ  F  L  V"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gower_matrix = gower.gower_matrix(factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez_compressed('Full_gower_matrix.npz', gw=gower_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gower_matrix = np.load('Full_gower_matrix.npz')['gw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32375, 32375)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gower_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMedoids(D, k, tmax=100):\n",
    "    # determine dimensions of distance matrix D\n",
    "    m, n = D.shape\n",
    "    \n",
    "    # randomly initialize an array of k medoid indices\n",
    "    M = np.sort(np.random.choice(n, k))\n",
    "    \n",
    "    # create a copy of the array of medoid indices\n",
    "    Mnew = np.copy(M)\n",
    "    \n",
    "    # initialize a dictionary to represent clusters\n",
    "    C = {}\n",
    "    \n",
    "    for t in range(tmax): # t iterates over the convergence cycles\n",
    "        # determine clusters, i.e. arrays of data indices\n",
    "        J = np.argmin(D[:,M], axis=1)\n",
    "        for kappa in range(k):\n",
    "            C[kappa] = np.where(J==kappa)[0]\n",
    "        \n",
    "        # update cluster medoids\n",
    "        for kappa in range(k):\n",
    "            J = np.mean(D[np.ix_(C[kappa],C[kappa])],axis=1)\n",
    "            j = np.argmin(J)\n",
    "            Mnew[kappa] = C[kappa][j]\n",
    "            np.sort(Mnew)\n",
    "                \n",
    "        # check for convergence\n",
    "        if np.array_equal(M, Mnew):\n",
    "            break\n",
    "                \n",
    "        M = np.copy(Mnew)\n",
    "    \n",
    "    else:\n",
    "        # final update of cluster memberships\n",
    "        J = np.argmin(D[:,M], axis=1)\n",
    "        for kappa in range(k):\n",
    "            C[kappa] = np.where(J==kappa)[0]\n",
    "                \n",
    "    # return results\n",
    "    return M, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "medoids, clusters = kMedoids(gower_matrix, 5, tmax=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medoids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "402",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-fa7ab5d108bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmedoids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 402"
     ]
    }
   ],
   "source": [
    "active[medoids[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3848038/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = random.sample(active.items(), 1000)\n",
    "test_dict = {}\n",
    "for i in range(len(test)):\n",
    "    test_dict[test[i][0]] = test[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = '<?xml version=\"1.0\" encoding=\"utf-8\"?>'\n",
    "graphml_open = '<graphml xmlns=\"http://graphml.graphdrawing.org/xmlns\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \\\n",
    "    xsi:schemaLocation=\"http://graphml.graphdrawing.org/xmlns  http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd\">'\n",
    "graph_open = '<graph edgedefault=\"undirected\">'\n",
    "\n",
    "close = '</graph>\\n</graphml>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hammet distance = 0 if the aa matches at all positions\n",
    "def hammet_distance(s1, s2, pos_aa):\n",
    "    d = 0\n",
    "    if (len(s1) != len(pos_aa)) or (len(s2) != len(pos_aa)):\n",
    "        d += 2\n",
    "\n",
    "    for p in pos_aa.keys():\n",
    "        if s1[p] != s2[p]:\n",
    "            d += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of edges\n",
    "def list_edge_nodes(graph_dict, pos_aa):\n",
    "    node_pairs = []\n",
    "    ordered_variants = list(graph_dict.keys())\n",
    "    for i in range(len(ordered_variants)):\n",
    "        short1 = ordered_variants[i]\n",
    "        s1 = graph_dict[short1]\n",
    "        for j in range(i+1, len(ordered_variants)):\n",
    "            short2 = ordered_variants[j]\n",
    "            s2 = graph_dict[short2]\n",
    "\n",
    "            h_dis = hammet_distance(s1, s2, pos_aa)\n",
    "            if h_dis == 1:\n",
    "                node_pairs.append((short1, short2))\n",
    "    return node_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPHML functions\n",
    "\n",
    "# create nodes\n",
    "def gml_write_node(short, file):\n",
    "    print('<node id=\\\"{node}\"/>'.format(node=short), sep=\"\", file=file)\n",
    "\n",
    "def gml_list_edge_strings(node_pairs):\n",
    "    edge_strings = []\n",
    "    for pair in node_pairs:\n",
    "        edge_id = '-'.join(pair)\n",
    "        one_edge = '<edge id=\"{id}\" source=\"{s}\" target=\"{t}\"/>'.format(\n",
    "            id=edge_id, s=pair[0], t=pair[1])\n",
    "        edge_strings.append(one_edge)\n",
    "    return edge_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write the graph file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_graphml(graph_dict, filename):\n",
    "    with open (filename, 'w') as f:\n",
    "        # print the GRAPHML header definitions\n",
    "        print(header, graphml_open, graph, file=f, sep='\\n')\n",
    "\n",
    "        # write nodes\n",
    "        for short in graph_dict.keys():\n",
    "            gml_write_node(short, f)\n",
    "\n",
    "        # write edges\n",
    "        node_pairs = list_edge_nodes(graph_dict, pos_aa)\n",
    "        edge_strings = gml_list_edge_strings(node_pairs)\n",
    "        f.writelines(edge_strings)\n",
    "\n",
    "        # end the graph and graphml\n",
    "        print(close, file=f)\n",
    "    \n",
    "    return node_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges = write_graphml(test_dict, 'test.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_edges = write_graphml(active, 'active.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence similarity network analysis with NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f17d728e971c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import networkx as nx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
