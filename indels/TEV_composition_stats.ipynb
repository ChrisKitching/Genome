{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import statistics\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "from string import ascii_lowercase\n",
    "\n",
    "from Bio import AlignIO, SeqIO\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import MutableSeq, translate\n",
    "\n",
    "from ind import findEnds\n",
    "from output import printErrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of reference fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dna_subs(read, ref, verbose=False, start_offset=0, end_trail=0):\n",
    "    \"\"\"\n",
    "    @ read, ref: MutableSeq objects\n",
    "    :return errors - tuple (position, expected triplet, actual triplet, ) / none if broken read\n",
    "    \n",
    "    This is intended purely for counting PCR polymerase substitutions.\n",
    "    The assumption is that the reference contains only the gene of interest.\n",
    "    As for HGVS, the starting offset and number of trailing nt are variable\n",
    "    Letter by letter report mutations in NGS read, all counts 1- based in result (code in 0-count for Python).\n",
    "    - substitution: 78C = nt 78 in reference is changed to C, assuming reference starts with 1\n",
    "    - deletions: 78d6 = 6 nt deleted starting with 78: 1-77, d6, 84-end\n",
    "    - insertion: 78iATC = seq ATC inserted between 78 and 79\n",
    "    \"\"\"\n",
    "\n",
    "    if read is None:\n",
    "        if verbose:\n",
    "            print('no read provided')\n",
    "        return\n",
    "\n",
    "#     # find the ends of the read\n",
    "    ends = findEnds(read, ref, start_offset)\n",
    "\n",
    "    # scan read & reference letter by letter, counting position in reference\n",
    "    # reads have been trimmed so that reference starts @ offset=3 by default (0,1,2 is the extra triplet)\n",
    "    dna_errors = []\n",
    "    ref_index = ends.get('start') - start_offset\n",
    "    i = ends.get('start')\n",
    "    max_i = len(ref) - end_trail\n",
    "    \n",
    "    # check for indels\n",
    "    if str(read).find('-') != -1:\n",
    "        if verbose:\n",
    "            print('indel')\n",
    "        return\n",
    "    elif str(ref).find('-') != -1:\n",
    "        if verbose:\n",
    "            print('indel')\n",
    "        return\n",
    "    elif len(ref) != len(read):\n",
    "        if verbose:\n",
    "            print('indel')\n",
    "        return\n",
    "    else:\n",
    "        # continue on to scand the read for substitutions\n",
    "        while i < ends.get('end'):\n",
    "            if i > max_i:\n",
    "                break\n",
    "            # check for differences\n",
    "            if read[i] == ref[i]:\n",
    "                ref_index += 1\n",
    "                i += 1\n",
    "\n",
    "            else:\n",
    "                # substitution\n",
    "                # don't report N as mutations\n",
    "                if str(read[i]) == \"N\" or str(read[i]) == \"n\":\n",
    "                    i += 1\n",
    "                    ref_index += 1\n",
    "                    continue\n",
    "                elif ref_index > 0:\n",
    "                    dna_errors += [(str(ref_index + 1), 's', str(read[i]))]\n",
    "                i += 1\n",
    "                ref_index += 1\n",
    "\n",
    "\n",
    "    return tuple(dna_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../full_fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fixed length of sequences means that pre-aligning the sequences is not necessary. I can directly compare each FASTA read with the reference.\n",
    "\n",
    "## Error rate of sequencing: the WT files\n",
    "\n",
    "#### WT first half sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_variant_counts = {}\n",
    "error_summary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('146', 's', 'A'), ('149', 's', 'C'))\n",
      "\n",
      "0    5    10   15   20   25   30   35   40   45   50   55   60   65   70   75   80   85   90   95   \n",
      "|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....\n",
      "\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\n",
      "\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[31mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[31mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\n",
      "\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\n",
      "\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\n",
      "{'TEV-wt-fw': defaultdict(<class 'int'>, {'nNs': 1})}\n",
      "{'TEV-wt-fw': defaultdict(<class 'int'>, {0: 1715, 1: 28, 2: 1})}\n"
     ]
    }
   ],
   "source": [
    "# start with the forward sequenced on the WT\n",
    "with open(\"./TEV_fw.fa\", \"r\") as f:\n",
    "    ref_seq =  SeqIO.read(f, \"fasta\", alphabet=IUPAC.ambiguous_dna)\n",
    "\n",
    "# files = glob.glob(\"./*_fw*\")\n",
    "files = ['./TEV-F.fa']\n",
    "\n",
    "for f in files:\n",
    "    # make a dictionary to collect the counts\n",
    "    # fname = f[34:]\n",
    "    fname = \"TEV-wt-fw\"\n",
    "    dna_variant_counts[fname] = defaultdict(int)\n",
    "    error_summary[fname] = defaultdict(int)\n",
    "    \n",
    "    for var_record in SeqIO.parse(f, \"fasta\", alphabet=IUPAC.ambiguous_dna):\n",
    "        number_of_nNs = var_record.seq.count('N') + var_record.seq.count('n')\n",
    "        if number_of_nNs > 10:\n",
    "            error_summary[fname]['nNs'] += 1\n",
    "            continue\n",
    "            \n",
    "        dna_d = find_dna_subs(var_record.seq, ref_seq.seq, start_offset = 0, end_trail = 0)\n",
    "        if dna_d is None:\n",
    "            error_list.append(var_record)\n",
    "        else:\n",
    "            dna_variant_counts[fname][len(dna_d)] += 1\n",
    "            if len(dna_d) > 1:\n",
    "                printErrors(dna_d, var_record.seq, ref_seq.seq, True)\n",
    "                \n",
    "print(error_summary)\n",
    "print(dna_variant_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we can dismiss the read with 9 mutations, it appears to be a low quality read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors per read: 0.017201834862385322\n",
      "errors per base: 4.7782874617737003e-05\n"
     ]
    }
   ],
   "source": [
    "# sequencing error rate:\n",
    "num_seq_errors = 28 + 2\n",
    "num_seq_reads = (sum(dna_variant_counts['TEV-wt-fw'].values()))\n",
    "print(\"errors per read:\", num_seq_errors/num_seq_bases)\n",
    "print(\"errors per base:\", num_seq_errors/(num_seq_bases*len(ref_seq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected ion torrent error rate is an error in 1.7% of reads, so we're about there.\n",
    "https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-13-341"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTION: \n",
    "It might be worth to look if there's a bias in random sequencing errors, there's probably lit for that.\n",
    "Possibly keep checks on the reads for number of NNNs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WT second half sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('275', 's', 'C'), ('277', 's', 'G'))\n",
      "\n",
      "0    5    10   15   20   25   30   35   40   45   50   55   60   65   70   75   80   85   90   95   \n",
      "|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....\n",
      "\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\n",
      "\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\n",
      "\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[31mC\u001b[0m\u001b[32mC\u001b[0m\u001b[31mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\n",
      "\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\n",
      "(('119', 's', 'T'), ('259', 's', 'A'))\n",
      "\n",
      "0    5    10   15   20   25   30   35   40   45   50   55   60   65   70   75   80   85   90   95   \n",
      "|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....\n",
      "\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\n",
      "\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[31mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\n",
      "\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[31mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\n",
      "\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\n",
      "(('275', 's', 'C'), ('277', 's', 'G'))\n",
      "\n",
      "0    5    10   15   20   25   30   35   40   45   50   55   60   65   70   75   80   85   90   95   \n",
      "|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....|....\n",
      "\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\n",
      "\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\n",
      "\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[31mn\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[31mC\u001b[0m\u001b[32mC\u001b[0m\u001b[31mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\n",
      "\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mG\u001b[0m\u001b[32mC\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mC\u001b[0m\u001b[32mT\u001b[0m\u001b[32mC\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mG\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\u001b[32mT\u001b[0m\u001b[32mT\u001b[0m\u001b[32mA\u001b[0m\u001b[32mA\u001b[0m\n",
      "{'TEV-wt-fw': defaultdict(<class 'int'>, {'nNs': 1}), 'TEV-wt-rv': defaultdict(<class 'int'>, {'nNs': 12})}\n",
      "{'TEV-wt-fw': defaultdict(<class 'int'>, {0: 1715, 1: 28, 2: 1}), 'TEV-wt-rv': defaultdict(<class 'int'>, {0: 2384, 1: 28, 2: 3})}\n"
     ]
    }
   ],
   "source": [
    "# start with the forward sequenced on the WT\n",
    "with open(\"./TEV_rv.fa\", \"r\") as f:\n",
    "    ref_seq =  SeqIO.read(f, \"fasta\", alphabet=IUPAC.ambiguous_dna)\n",
    "\n",
    "# files = glob.glob(\"./*_fw*\")\n",
    "files = ['./TEV-R.fa']\n",
    "\n",
    "for f in files:\n",
    "    # make a dictionary to collect the counts\n",
    "    # fname = f[34:]\n",
    "    fname = \"TEV-wt-rv\"\n",
    "    dna_variant_counts[fname] = defaultdict(int)\n",
    "    error_summary[fname] = defaultdict(int)\n",
    "    \n",
    "    for var_record in SeqIO.parse(f, \"fasta\", alphabet=IUPAC.ambiguous_dna):\n",
    "        number_of_nNs = var_record.seq.count('N') + var_record.seq.count('n')\n",
    "        if number_of_nNs > 10:\n",
    "            error_summary[fname]['nNs'] += 1\n",
    "            continue\n",
    "            \n",
    "        dna_d = find_dna_subs(var_record.seq, ref_seq.seq, start_offset = 0, end_trail = 0)\n",
    "        if dna_d is None:\n",
    "            error_list.append(var_record)\n",
    "        else:\n",
    "            dna_variant_counts[fname][len(dna_d)] += 1\n",
    "            if len(dna_d) > 1:\n",
    "                printErrors(dna_d, var_record.seq, ref_seq.seq, True)\n",
    "                \n",
    "print(error_summary)\n",
    "print(dna_variant_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors per read: 0.017775229357798166\n",
      "errors per base: 5.107824528102921e-05\n"
     ]
    }
   ],
   "source": [
    "# sequencing error rate second half:\n",
    "num_seq_errors = 28 + 3\n",
    "num_seq_reads = (sum(dna_variant_counts['TEV-wt-rv'].values()))\n",
    "print(\"errors per read:\", num_seq_errors/num_seq_bases)\n",
    "print(\"errors per base:\", num_seq_errors/(num_seq_bases*len(ref_seq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial library composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"./*_fw*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['H_fw_1.fa', 'H_fw_3.fa', 'H_fw_5.fa', \n",
    "                'H_fw_7.fa', 'H_fw_9.fa', 'H_fw_11.fa', \n",
    "                'L_fw_1.fa','L_fw_3.fa', 'L_fw_5.fa', \n",
    "                'L_fw_7.fa', 'L_fw_9.fa', 'L_fw_11.fa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = OrderedDict()\n",
    "\n",
    "for fname in column_order:\n",
    "    df[fname] = [dna_variant_counts[fname][i] for i in range(max_mutations +1)]\n",
    "    \n",
    "pd.DataFrame.from_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's analyse to all second half sequences\n",
    "with open(\"./TEV_rv.fa\", \"r\") as f:\n",
    "    wt_end =  SeqIO.read(f, \"fasta\", alphabet=IUPAC.ambiguous_dna)\n",
    "\n",
    "dna_variant_counts = {}\n",
    "\n",
    "files = glob.glob(\"/home/mp/InDelScanner/input_fasta/*_rv*\")\n",
    "\n",
    "for f in files:\n",
    "    # make a dictionary to collect the counts\n",
    "    fname = f[34:]\n",
    "    dna_variant_counts[fname] = defaultdict(int)\n",
    "    \n",
    "    for var_record in SeqIO.parse(f, \"fasta\", alphabet=IUPAC.ambiguous_dna):\n",
    "        dna_d = find_dna_subs(var_record.seq, wt_end.seq, start_offset = 0, end_trail = 0)\n",
    "        if dna_d is None:\n",
    "            print(var.record)\n",
    "        else:\n",
    "            dna_variant_counts[fname][len(dna_d)] += 1\n",
    "\n",
    "observed_counts = [list(dna_variant_counts[i].keys()) for i in dna_variant_counts.keys()]\n",
    "max_mutations = max(list(itertools.chain.from_iterable(observed_counts))) #  this tolerates an empty input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_variant_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['H_rv_1.fa', 'H_rv_3.fa','H_rv_5.fa',\n",
    "                'H_rv_7.fa', 'H_rv_9.fa','H_rv_11.fa',\n",
    "                'L_rv_1.fa', 'L_rv_3.fa', 'L_rv_5.fa',\n",
    "                'L_rv_7.fa', 'L_rv_9.fa', 'L_rv_11.fa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = OrderedDict()\n",
    "\n",
    "for fname in column_order:\n",
    "    df[fname] = [dna_variant_counts[fname][i] for i in range(max_mutations +1)]\n",
    "    \n",
    "pd.DataFrame.from_dict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots: number of nucleotide changes per variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nt_subs_disaggregated(ref_file, files_to_analyse, dna_variant_counts):\n",
    "    \n",
    "    for f in files_to_analyse:\n",
    "        # make a dictionary to collect the counts\n",
    "        fname = f[34:]\n",
    "        dna_variant_counts[fname] = []\n",
    "\n",
    "        for var_record in SeqIO.parse(f, \"fasta\", alphabet=IUPAC.ambiguous_dna):\n",
    "            dna_d = find_dna_subs(var_record.seq, ref_file.seq, start_offset = 0, end_trail = 0)\n",
    "            if dna_d is None:\n",
    "                print(var.record)\n",
    "            else:\n",
    "                # filter out the indels\n",
    "                # get the tuple[1] positions which should all be 's' for substitutions\n",
    "                s = 0\n",
    "                for p in dna_d:\n",
    "                    if p[1] == 's':\n",
    "                        s += 1\n",
    "                    else:\n",
    "                        print(dna_d)\n",
    "                        break\n",
    "\n",
    "                dna_variant_counts[fname].append(s)\n",
    "                \n",
    "    return dna_variant_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_variant_counts = {}\n",
    "\n",
    "with open(\"./TEV_rv.fa\", \"r\") as f:\n",
    "    wt_end =  SeqIO.read(f, \"fasta\", alphabet=IUPAC.ambiguous_dna)\n",
    "\n",
    "files = glob.glob(\"/home/mp/InDelScanner/input_fasta/*_rv*\")\n",
    "\n",
    "dna_variant_counts = count_nt_subs_disaggregated(wt_end, files, dna_variant_counts)\n",
    "\n",
    "# now add the forward files\n",
    "\n",
    "with open(\"./TEV_fw.fa\", \"r\") as f:\n",
    "    wt_fw =  SeqIO.read(f, \"fasta\", alphabet=IUPAC.ambiguous_dna)\n",
    "\n",
    "files = glob.glob(\"/home/mp/InDelScanner/input_fasta/*_fw*\")\n",
    "\n",
    "dna_variant_counts = count_nt_subs_disaggregated(wt_fw, files, dna_variant_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the desired order for boxplots\n",
    "label_order = ['1_fw', '1_rv', '3_fw', '3_rv', '5_fw', '5_rv', '7_fw', '7_rv', '9_fw', '9_rv', '11_fw', '11_rv']\n",
    "\n",
    "file_order_high = ['H_fw_1.fa', 'H_rv_1.fa',\n",
    "                   'H_fw_3.fa', 'H_rv_3.fa',\n",
    "                   'H_fw_5.fa', 'H_rv_5.fa', \n",
    "                   'H_fw_7.fa', 'H_rv_7.fa', \n",
    "                   'H_fw_9.fa', 'H_rv_9.fa',\n",
    "                   'H_fw_11.fa', 'H_rv_11.fa']\n",
    "\n",
    "file_order_low = ['L_fw_1.fa', 'L_rv_1.fa',  \n",
    "                  'L_fw_3.fa', 'L_rv_3.fa', \n",
    "                  'L_fw_5.fa', 'L_rv_5.fa', \n",
    "                  'L_fw_7.fa', 'L_rv_7.fa', \n",
    "                  'L_fw_9.fa', 'L_rv_9.fa',\n",
    "                  'L_fw_11.fa', 'L_rv_11.fa']             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = [1, 2, \n",
    "             4, 5,\n",
    "             7, 8,\n",
    "             10, 11, \n",
    "             13, 14, \n",
    "             16, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [7,7]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.boxplot([dna_variant_counts[k] for k in file_order_high], positions = positions, widths = 0.75,\n",
    "          showmeans=True, meanline=True)\n",
    "ax.set_xticklabels(label_order)\n",
    "ax.set_ylim([0, 28])\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=45)\n",
    "ax.set_xlabel('Sequencing population')\n",
    "ax.set_ylabel('Number of nucleotide substitutions')\n",
    "ax.set_title('High mutational load lineage (μ=1.5%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [7,7]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.boxplot([dna_variant_counts[k] for k in file_order_low], positions = positions, widths = 0.75,\n",
    "          showmeans=True, meanline=True)\n",
    "ax.set_xticklabels(label_order)\n",
    "ax.set_ylim([0, 28])\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=45)\n",
    "ax.set_xlabel('Sequencing population')\n",
    "ax.set_ylabel('Number of nucleotide substitutions')\n",
    "ax.set_title('Low mutational load lineage (μ=0.5%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add both distributions together: model each sequence A added to each sequence B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_variant_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_order_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_order = ['Round 1', 'Round 3', 'Round 5', 'Round 7', 'Round 9', 'Round 11']\n",
    "\n",
    "full_length_dna = {k : [] for k in round_order}\n",
    "\n",
    "# let's start with high\n",
    "f_order = file_order_high\n",
    "# I can use the fact that the files are ordered in pairs for the boxplots\n",
    "for i in range(len(round_order)):\n",
    "    round_name = round_order[i]\n",
    "    fw_name = f_order[2*i]\n",
    "    rv_name = f_order[2*i+1]\n",
    "    for variant_fw in dna_variant_counts[fw_name]:\n",
    "        for variant_rv in dna_variant_counts[rv_name]:\n",
    "            full_length_dna[round_name].append(variant_fw + variant_rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [7,7]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.boxplot(full_length_dna.values(), showmeans=True, meanline=True, showfliers=False)\n",
    "ax.set_xticklabels(round_order)\n",
    "ax.set_ylim([0, 40])\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=45)\n",
    "ax.set_xlabel('Evolution population')\n",
    "ax.set_ylabel('Number of nucleotide substitutions')\n",
    "ax.set_title('High mutational load lineage (μ=1.5%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in full_length_dna.items():\n",
    "    try:\n",
    "        m = statistics.median(v)\n",
    "    except :\n",
    "        continue\n",
    "    print(k, \"Median nt changes:\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_order = ['Round 1', 'Round 3', 'Round 5', 'Round 7', 'Round 9', 'Round 11']\n",
    "\n",
    "full_length_dna = {k : [] for k in round_order}\n",
    "\n",
    "# let's start with high\n",
    "f_order = file_order_low\n",
    "# I can use the fact that the files are ordered in pairs for the boxplots\n",
    "for i in range(len(round_order)):\n",
    "    round_name = round_order[i]\n",
    "    fw_name = f_order[2*i]\n",
    "    rv_name = f_order[2*i+1]\n",
    "    print(rv_name, fw_name)\n",
    "    for variant_fw in dna_variant_counts[fw_name]:\n",
    "        for variant_rv in dna_variant_counts[rv_name]:\n",
    "            full_length_dna[round_name].append(variant_fw + variant_rv)\n",
    "            \n",
    "plt.rcParams[\"figure.figsize\"] = [7,7]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.boxplot(full_length_dna.values(), showmeans=True, meanline=True, showfliers=False)\n",
    "ax.set_xticklabels(round_order)\n",
    "ax.set_ylim([0, 40])\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation=45)\n",
    "ax.set_xlabel('Evolution population')\n",
    "ax.set_ylabel('Number of nucleotide substitutions')\n",
    "ax.set_title('Low mutational load lineage (μ=0.5%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in full_length_dna.items():\n",
    "    print(k, \"Median nt changes:\", statistics.median(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protein sequence variation\n",
    "\n",
    "-\tForward files contain AA 2-121\n",
    "-\tReverse files contain AA 122-236, also in forward read orientation; thus naming the files as reverse is misleading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_protein_diff(read, ref, verbose=False, start_offset=3, end_trail=3):\n",
    "\n",
    "    # quality control\n",
    "    if read is None:\n",
    "        return None, None\n",
    "    ends = findEnds(read, ref, start_offset)\n",
    "#     if not endMatch(read, ref, ends):\n",
    "#         return None, None\n",
    "\n",
    "    newread = read\n",
    "    newref = ref\n",
    "\n",
    "    # scan reference triplet by triplet\n",
    "    # move letters when encountering an indel\n",
    "    prot_errors = []\n",
    "    prot_short = []\n",
    "\n",
    "    i = ends.get('aligned')\n",
    "    ref_index = int((ends.get('aligned') - start_offset)/3) + 1  # reference amino acid index\n",
    "    max_i = len(ref) - end_trail\n",
    "\n",
    "    while i <= ends.get('end'):\n",
    "        if i > max_i:\n",
    "            break\n",
    "\n",
    "        if newread is None:\n",
    "            break\n",
    "        ref_codon = newref[i:i+3]\n",
    "        read_codon = newread[i:i+3]\n",
    "\n",
    "        if '-' in read_codon:  # found a deletion\n",
    "            # Check if this is the last acid, and it's incomplete, ignore it.\n",
    "            if re.search('[ATGC]', str(newread[i + 3:])) is None:\n",
    "                break\n",
    "\n",
    "            if '-' in ref_codon:  # something very broken\n",
    "                prot_errors.append((ref_index, 'f'))\n",
    "                prot_short.append('f')\n",
    "                break\n",
    "            elif read_codon == '---':  # single codon deletion\n",
    "                if ref_index > 0:\n",
    "                    prot_errors += [(ref_index, 'd')]\n",
    "                    prot_short.append(str(ref_index) + 'Δ')\n",
    "                i += 3\n",
    "                ref_index += 1\n",
    "\n",
    "            else:  # check it's not a frame shift\n",
    "                l = indel_len(newread, i)\n",
    "                if l % 3 != 0:\n",
    "                    prot_errors.append((ref_index, 'f'))\n",
    "                    prot_short.append('f')\n",
    "                    break\n",
    "                # realign gap and repeat loop at same position to compare the codons\n",
    "                gap = findGap(newread[i - 1:])\n",
    "                gap = (gap[0] + i - 1, gap[1] + i - 1)\n",
    "                newread = gapAlign(newread, gap, start_offset)\n",
    "                continue\n",
    "\n",
    "        elif '-' in ref_codon:  # found an insertion\n",
    "            l = indel_len(newref, i)\n",
    "            if l % 3 != 0:\n",
    "                prot_errors.append((ref_index, 'f'))\n",
    "                prot_short.append('f')\n",
    "                break\n",
    "            gap = findGap(newref[i-1:])\n",
    "            if gap[0] == 1:  # insertion after codon\n",
    "                insertion = newread[gap[0] + i - 1:gap[1] + i - 1]\n",
    "                if '-' in insertion:\n",
    "                    prot_errors.append((ref_index, 'f'))\n",
    "                    prot_short.append('f')\n",
    "                    break\n",
    "                if ref_index > 0:\n",
    "                    prot_errors.append((ref_index - 1, 'i', str(translate(insertion)))) # position before + insertion\n",
    "                    stop, inslist = format_insertion(ref_index - 1, insertion)\n",
    "                    prot_short += inslist\n",
    "                    if stop:\n",
    "                        break\n",
    "                i += l\n",
    "                ref_index += 1\n",
    "            else:  # realign gap and repeat loop at same position to compare the codons\n",
    "                gap = (gap[0] + i - 1, gap[1] + i - 1)\n",
    "                newref = gapAlign(newref, gap, start_offset)\n",
    "                continue\n",
    "\n",
    "        elif translate(read_codon) != translate(ref_codon):  # must be a substitution\n",
    "            if ref_index > 0:\n",
    "                prot_errors.append((ref_index, 's', str(translate(read_codon))))\n",
    "                prot_short.append(str(translate(ref_codon) + str(ref_index) + str(translate(read_codon))))\n",
    "            if str(translate(read_codon)) == '*':\n",
    "                break\n",
    "            i += 3\n",
    "            ref_index += 1\n",
    "\n",
    "        else:\n",
    "            i += 3\n",
    "            ref_index += 1\n",
    "\n",
    "    if verbose:\n",
    "        print(prot_errors)\n",
    "\n",
    "    if prot_short == []:\n",
    "        short = 'wt'\n",
    "    else:\n",
    "        short = '/'.join(prot_short)\n",
    "\n",
    "    return tuple(prot_errors), short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test protein_diff function for numbering\n",
    "\n",
    "test_ref =  \"AAGAGCTTGTTTAAGGGGCCGCGTGATTACAACCCGATATCGAGCACCATTTGTCATTTGACGAATGAATCTGATGGGCACACAACATCGTTGTATGGTATTGGATTTGGTCCCTTCATCATTACAAACAAGCACTTGTTTAGAAGAAATAATGGAACACTGTTGGTCCAATCACTACATGGTGTATTCAAGGTCAAGAACACCACGACTTTGCAACAACACCTCATTGATGGGAGGGACATGATAATTATTCGCATGCCTAAGGATTTCCCACCATTTCCTCAAAAGCTGAAATTTAGAGAGCCACAAAGGGAAGAGCGCATATGTCTTGTGACAACCAACTTCCAAACTAAGAGCATG\"\n",
    "test_read = \"AAGAGCTTGTTTAAGGGGCCGCGTGATTACAACCCGATATCGAGCACCATTTGTCATTTGACGAATGAATCTGATGGGCACACAACATCGCTGTATGGTATTGGATTTGGTCCCTTCGTCATTACAAACAAGCACTTGTTTAGAAGAAATAATGGAACACTGTTGGTCCAATCACTACATGGTGTATTCAAGGTCAAGAACACCACGACTTTGCAACAACACCTCATTGATGGGAGGGACATGATAATTATTCGCATGCCTAAGGATTTCCCACCATTTCCTCAAAAGCTGACATTTAGAGAGCCACAAAGGGAAGAGCGCCTATGTCTTGTGACAACCAACTTCCAAACTAAGAGCAGG\"\n",
    "\n",
    "print(find_dna_subs(test_read, test_ref))\n",
    "find_protein_diff(test_read, test_ref, start_offset = -3, end_trail = 0)\n",
    "\n",
    "# since first AA should be position 2, use start_offset -3\n",
    "# I need to disable end matching from the find_protein_diff function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's analyse all first half sequences\n",
    "with open(\"./TEV_fw.fa\", \"r\") as f:\n",
    "    ref_seq =  SeqIO.read(f, \"fasta\", alphabet=IUPAC.ambiguous_dna)\n",
    "\n",
    "variant_counts = {}\n",
    "\n",
    "files = glob.glob(\"/home/mp/InDelScanner/input_fasta/*_fw*\")\n",
    "\n",
    "for f in files:\n",
    "    # make a dictionary to collect the counts\n",
    "    fname = f[34:]\n",
    "    variant_counts[fname] = defaultdict(int)\n",
    "    \n",
    "    for var_record in SeqIO.parse(f, \"fasta\", alphabet=IUPAC.ambiguous_dna):\n",
    "        dna_d = find_dna_subs(var_record.seq, ref_seq.seq, start_offset = 0, end_trail = 0)\n",
    "        if dna_d is None:\n",
    "            print(var.record)\n",
    "        else:\n",
    "            protein_d, prot_short = find_protein_diff(var_record.seq, ref_seq.seq, start_offset = -3, end_trail = 0)\n",
    "            variant_counts[fname][len(protein_d)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_counts = [list(variant_counts[i].keys()) for i in variant_counts.keys()]\n",
    "max_mutations = max(list(itertools.chain.from_iterable(observed_counts))) #  this tolerates an empty input file\n",
    "max_mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['H_fw_1.fa', 'H_fw_3.fa', 'H_fw_5.fa', \n",
    "                'H_fw_7.fa', 'H_fw_9.fa', 'H_fw_11.fa', \n",
    "                'L_fw_1.fa','L_fw_3.fa', 'L_fw_5.fa', \n",
    "                'L_fw_7.fa', 'L_fw_9.fa', 'L_fw_11.fa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = OrderedDict()\n",
    "\n",
    "for fname in column_order:\n",
    "    df[fname] = [variant_counts[fname][i] for i in range(max_mutations +1)]\n",
    "    \n",
    "pd.DataFrame.from_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And repeat the process for the second half of protein sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's analyse all first half sequences\n",
    "with open(\"./TEV_rv.fa\", \"r\") as f:\n",
    "    ref_seq =  SeqIO.read(f, \"fasta\", alphabet=IUPAC.ambiguous_dna)\n",
    "\n",
    "variant_counts = {}\n",
    "\n",
    "files = glob.glob(\"/home/mp/InDelScanner/input_fasta/*_rv*\")\n",
    "\n",
    "for f in files:\n",
    "    # make a dictionary to collect the counts\n",
    "    fname = f[34:]\n",
    "    variant_counts[fname] = defaultdict(int)\n",
    "    \n",
    "    for var_record in SeqIO.parse(f, \"fasta\", alphabet=IUPAC.ambiguous_dna):\n",
    "        dna_d = find_dna_subs(var_record.seq, ref_seq.seq, start_offset = 0, end_trail = 0)\n",
    "        if dna_d is None:\n",
    "            print(var.record)\n",
    "        else:\n",
    "            protein_d, prot_short = find_protein_diff(var_record.seq, ref_seq.seq, start_offset = -3, end_trail = 0)\n",
    "            variant_counts[fname][len(protein_d)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_counts = [list(variant_counts[i].keys()) for i in variant_counts.keys()]\n",
    "max_mutations = max(list(itertools.chain.from_iterable(observed_counts))) #  this tolerates an empty input file\n",
    "max_mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['H_rv_1.fa', 'H_rv_3.fa','H_rv_5.fa',\n",
    "                'H_rv_7.fa', 'H_rv_9.fa','H_rv_11.fa',\n",
    "                'L_rv_1.fa', 'L_rv_3.fa', 'L_rv_5.fa',\n",
    "                'L_rv_7.fa', 'L_rv_9.fa', 'L_rv_11.fa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make aggregate dict for easy variant counts presentation & mutation rate calculation\n",
    "dct = OrderedDict()\n",
    "\n",
    "for fname in column_order:\n",
    "    dct[fname] = [variant_counts[fname][i] for i in range(max_mutations +1)]\n",
    "    \n",
    "df = pd.DataFrame.from_dict(dct)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ref_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand the boxplots for counting mutations to consider different types of AA mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start looking at the type of protein change: synonimous, non-synonimous, stop\n",
    "with open(\"./TEV_fw.fa\", \"r\") as f:\n",
    "    ref_seq =  SeqIO.read(f, \"fasta\", alphabet=IUPAC.ambiguous_dna)\n",
    "\n",
    "variant_counts = {}\n",
    "\n",
    "files = glob.glob(\"/home/mp/InDelScanner/input_fasta/*_fw*\")\n",
    "\n",
    "for f in files:\n",
    "    # make a dictionary to collect the counts\n",
    "    fname = f[34:]\n",
    "    variant_counts[fname] = defaultdict(int)\n",
    "    \n",
    "    for var_record in SeqIO.parse(f, \"fasta\", alphabet=IUPAC.ambiguous_dna):\n",
    "        dna_d = find_dna_subs(var_record.seq, ref_seq.seq, start_offset = 0, end_trail = 0)\n",
    "        if dna_d is None:\n",
    "            print(var.record)\n",
    "        else:\n",
    "            protein_d, prot_short = find_protein_diff(var_record.seq, ref_seq.seq, start_offset = -3, end_trail = 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
